Most would agree, the brain is complex. But, beyond metaphor, does the brain's complexity demand a paradigm shift in how we study its structure and function? I argue that complexity manifests in three domains – connectivity, dynamics, and information – and that unlocking their interactions will greatly advance our understanding of brain and cognition. The brain's complexity, evident at all scales and across the broad domains of structure and function, is widely acknowledged in neuroscience. Twenty-five years ago, complexity, if invoked at all [1], was seen as little more than a metaphor, a troublesome hurdle soon to be overcome by relentless aggregation of fine-grained empirical observations and ever more sophisticated technology. This mainly reductive enterprise has yielded spectacular advances. But the dominance of reductionism is on the wane, and the balance is shifting in favor of a complementary, more constructive or constructionist agenda. The continued surge of computation, the growing avalanche of observational data, and the advent of new quantitative fields such as network science have brought us to a point where it is possible, indeed inevitable, to tackle brain complexity head-on. In this forum, I offer a personal view of what the future may hold, and which research questions and directions will be important to pursue.

First, a brief note on the nature of complexity. The term does not apply to just any 'complicated' system with lots of moving parts. Instead, truly complex systems not only have many elements, but those elements are linked through an intricate web of interactions and connections, typically organized on different levels of scale. It is these interactions that give rise to novel, often surprising and counterintuitive properties. Such properties are 'emergent' as they are expressed only at larger scales and are completely absent at smaller scales. As the saying goes, the whole is greater than the sum of its parts, or 'more is different' [2]. Few systems offer a more clear-cut example of this than the brain. Mental and cognitive states are irreducible to the mechanics of the brain's individual elements; instead they emerge from their interactions, organizing large populations of such elements into complex distributed networks. The rules that govern this emergence remain elusive. Leibniz' lament 'that perception and that which depends on it are inexplicable on mechanical grounds, that is to say, by means of figures and motions' [3] has never been satisfactorily addressed.

The struggle to overcome Leibniz's gap has occupied science for centuries, and its failure has fostered systems of thought that divided mind from matter. But there is hope for progress in bridging the gap. The next 25 years are bound to bring breakthroughs on many specific questions, some long-standing and others that have not yet even been asked, facilitated through technologies that are inconceivable today. While specific predictions are hard to make, I believe significant breakthroughs will come from directly confronting the brain's complexity, shifting emphasis from decomposing the brain, reductively, into smaller and smaller bits towards a stronger focus on the principles that govern its operation as an integrated complex system. Three key ingredients will be central to that quest: the mutually interdependent domains of connectivity, dynamics, and information.

Connectivity has already become a core concept in neuroscience. Nevertheless, despite widespread use, the term is rarely carefully defined. The fundamental distinction between structural connectivity (material connections) and functional connectivity (statistical dependencies) is often neglected. Yet, this distinction is important to grasp, as the dialogue between structure and function animates much of the brain’s complexity. The fundamental and veridical status of structural connections motivated the original definition of the connectome as a comprehensive network map of anatomical connections [4]. Over the next 25 years, we will see significant inroads in connectomics, culminating in a complete map of neurons and synapses in a mammal, most likely the mouse. Such a map will be truly vast, summarized in a network composed of millions of nodes and billions of edges, presumably richly annotated with positional, geometric, cellular, molecular, and biophysical data. The impact on neuroscience will resemble the impact of mapping genomes on biology. While much will be learned about the structural code, the recurrent features and motifs underpinning circuit architecture, translating the code embedded in connectivity into neurobiologically realized function and behavior will pose many new questions. The last point is important. Drawing a complete map of the connectome is essential and necessary, but it is not in itself sufficient to capture or explain the diversity of neural states that enable the richness of behavior or generate the flow of experience. Connectivity does not equal cognition and hence, you are not your connectome. However, like a scaffold or skeleton, the connectome lends shape to the mind. Connectivity defines the space of what is possible, what can be physically realized. For example, the webs of causal influence mediated by neuronal signaling and how neurons can organize into communities and ensembles. Importantly, in defining what is possible, connectivity excludes that which is impossible and therefore inaccessible to biology and evolution. Connectivity does not, by itself, explain what brains do, but it firmly rules out what they cannot do.

Dynamics is essential to getting us closer to function [5]. It is well known that brain circuits and systems can produce a wide range of dynamical states, manifesting in ever-changing patterns of activation and coactivity. These states reflect the interplay of structural connections, cellular biophysics, plasticity, neuromodulation, sensory input, and the physical and social environment. Dynamic variability and sensitivity to momentary changes in internal state and external drive must be balanced against maintaining some level of stability and persistence, a trade-off perhaps best achieved when dynamics reflect both order and disorder, as in the elusive 'critical state' [6]. There is mounting empirical evidence that criticality is associated with ongoing and spontaneous brain activity, finely balancing intermittent variability with recurrence and thus creating a large and variable repertoire of brain states [7]. Intriguing links have been drawn between rich and diverse dynamic regimes and mental states, including levels of awareness [8], and the capacity for neural computation. Flexible dynamics also enable the crucial process of brain-wide communication, as signaling paths between spatially remote and functionally specialized regions are continually made and broken [9].

Information is intricately tied to fundamental concepts of entropy and patterns of statistical dependencies between ensembles of neurons. In the brain, information arises as connectivity shapes neuronal dynamics. Put differently, the dynamic patterns emerging on connectivity form state distributions that express which joint sets of neural elements affiliate into larger assemblies and coalitions. Dynamic manifolds constrain the flow of neural activity into low-dimensional attractors channeling and integrating different sources of neural activity. The resultant informational patterns range from synchrony, largely a reflection of redundant signals present across multiple neuronal elements, to much less well understood informational features involving higher-order interactions [10] such as synergy [11,12]. Redundancy has been a focus in the past, as it is ubiquitous and brings tangible benefits to neural function through the compounding effects of coherent activity. Synergy is much less well understood. In contrast to redundancy, synergy involves the integration of distinct sources of information such that subtracting any one source will diminish the integration of the whole. The musical integrity of a string quartet depends on each player's unique contributions and their mutual (re-entrant) coordination. The resultant performance is impervious to reductive decomposition: a work of complexity that is accessible and comprehensible only in its totality, as a whole. What enables or promotes synergy in neuronal populations, which neural circuits favor its genesis, and what it contributes to brain function is still largely unknown. Irreducible to elementary pairwise interactions, handily summarized in classic network diagrams, synergy dwells in the high-dimensional spaces created by connectivity and dynamics. For now, it is submerged beneath the relatively accessible surface of bivariate couplings, lurking within the combinatorically vast and almost completely unexplored ocean of multivariate information.

In a very literal sense, then, the brain's complexity is inexhaustible. But so are the potential motions of water molecules in the center of a hurricane. So, what is special about the brain? If one considers only the abundance of parts and pieces, the myriad ways in which they interact, and the sheer profusion of detail and variation, then brains are complex systems like many others found in nature. What sets brains apart is their constructive and creative potential, the astounding generative power inherent in the nexus of connectivity, dynamics, and information. A principled understanding of how connections shape dynamics and how dynamics create and integrate information is coming within reach. And yet, the capacity of the human nervous system, as part of an embodied organismic whole, to extend cognition into the real world, in the process of creating history, art, and culture, will continue to pose strong barriers to prediction and control. Therein, I suppose, lies a challenge as well as some measure of comfort.

